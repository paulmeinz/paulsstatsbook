# Set Theory and Probability 

In the course of research, behavioral scientists will often take samples of human behavior, e.g. a survey of a group of people, measurements of reaction time, etc. These samples will take some _outcome_, and most of us understand and have observed the inherent randomness of this act. That is to say, you might take the exact same sample in a carefully controlled circumstance and get different results every time.

Statisticians often refer to an analogous circumstance when talking about probability. Suppose we are able to describe all the possible outcomes of our sampling procedure. We take samples over and over again in the same circumstances, and each time the outcome changes. This is referred to as a **random experiment**. In order to familiarize you with some introductory concepts around probability, we're going to start in this context of a random experiment. First, we'll learn about sets and set theory in order to describe our **sample space**. This will also be useful in describing the form that outcomes of a random experiment may take. Then we'll more concretely define the randomness of our experiment by talking about **probability** - the quantification of randomness.

## Sets and Basic Set Theory

Before we get into it, we aren't going to learn set theory in it's entirety. That would be overly (and hilariously) ambitious. What we are going to learn will make understanding later sections easier, get your brain warmed up, and it'll make it a bit easier to understand set notation in other circumstances. The first step in conducting a random experiment is clearly defining all the possible outcomes of your sampling procedure. This is referred to as the **sample space**. Suppose we have five different possible outcomes in our sample space: A, B, C, D, and E. Let's call this sample space $S$. Then we would describe it like this:

$$
S = \{A, B, C, D, E\}
(\#eq:discreteset)
$$
That is to say we'll describe the set $S$ with curly braces, and on the inside of the curly braces, there shall be a list of _distinct_ elements of our set. The sample space above is an example of a **discrete** sample space - meaning it either contains a finite number of elements or it is _countable_. In this case, the sample space has a finite number of elements (five to be exact), so we can call it discrete.

On the other hand, describing a countable, but not necessarily finite, sample space can be tricky. My hope is you can gain a small sense for it from my explanation here. We'll see examples of it later. Specifically, a discrete sample space can also contain an _infinite_ number of elements - so long as those elements can be lined up one-to-one with the natural numbers (e.g. 1, 2, 3, 4, ...). That is, the elements can be "counted", albeit infinitely and forever. This is probably not the most intuitive definition for people who don't think about mathematics every day (it certainly wasn't for me). In another, more intuitive sense, a discrete sample space - finite or infinite - has elements with nothing in between them. In $S$ above, there is nothing in between A and B, for example. If your discrete set had an infinite number of elements, you could line them up (arbitrarily) with the natural numbers. And, after this alignment, you could find nothing between the first and second elements (or any given sequential pair for that matter).

With that point out of the way, we may also find ourselves sampling from a **continuous** sample space, e.g., all the values between and including 0 and 1 (e.g $0 \leq x \leq 1$). Since you can't enumerate all the values of a continuous sample space as we did with $S$ (people have "tried"; we'll talk about one such example later), we use a different form of notation. Suppose we have a continuous sample space $R$, then we would specify it as

$$
R = \{x\, | \, 0 \leq x \leq 1 \}
(\#eq:continuousset)
$$

The inclusion criteria for the set is written after the $|$ in the curly braces. The $|$ can be read loosely as meaning "where", so reading the whole thing in the curly braces left to right you get x _where_ $0 \leq x \leq 1$. Therefore, our set is all the $x$'s from 0 to 1. As an aside, continuous sample spaces can be found everywhere in the field of behavioral statistics. For reasons that will become apparent later, we shall nonetheless discuss these spaces with slightly less mathematical depth. 

Having discussed discrete and continuous sample spaces, it is now time to turn our attention towards sampling. Suppose we are randomly drawing a single item from our sample space $S = \{A, B, C, D, E\}$. We shall call a particular outcome an _event_. Events are described by a *subset* of the sample space. For example, we might say the event is $C = \{A, B, C\}$, and if our sample lands in the that subset (as either A, B, or C), then we shall say the event "occurred". For the sake of brevity, and positivity, I will referred to the occurrence of an event as a "success" (congratulations all around!). You can indicate a set is a subset by:

$$ C \subset S 
(\#eq:subset) $$

In this case, we are saying $C$ is a subset of $S$. We might also, for example say that our event is a single element $C_1 = \{A\}$ or the entire sample space $C_2 = \{A,B,C,D,E\}$. We can be as creative as we would like to be, so long as the event is in our sample space. 

Indeed, in practice we might want to get a little more creative in terms of the outcomes of our random experiment. Let's talk about a slightly more complicated scenario. Suppose we have two events $C_1 = \{A,B,C\}$ and $C_2 = \{B,C,D\}$, and we are interested in whether or not our randomly sampled element lands in $C_1$ or $C_2$. It's helpful here to consider the circumstances where this event occurs. Namely, If our realized element was an A, B, C, or D, then we would be successful (success!). That is to say, we've taken all the unique elements of either set and combined them into a new set. If our sample lands in that new subset, we can be confident that $C_1$ or $C_2$ occurred. There's a handy symbol that indicates this operation:

$$ C_1 \cup C_2 = \{A,B,C\}\:\cup\:\{B,C,D\} = \{A,B,C,D\} 
(\#eq:union) $$

This *union operator* ($\cup$) takes the unique elements of both sets and puts them into a set of their own. In this circumstance it is used synonymously with *or*. If the event of interest is our sample landing in $C_1$ OR $C_2$, then we would be successful if the event landed in the union of the two sets, e.g., all the unique elements from both sets. Here's another example, suppose we are interested in if our sample falls into $C_1 = \{A\}$ or $C_2 = \{B\}$. Then our event would occur if the element was A or B:

$$ \{A\}\:\cup\:\{B\} = \{A,B\} $$
Since we're being creative, let's consider another scenario (and a new operator!). Suppose we have our two previously described events - $C_1 = \{A,B,C\}$ and $C_2 = \{B,C,D\}$ - each a subset of $S$. Lets further say that we are interested in whether or not both events occur when we sample our element. That is, we shall be successful if our element falls in both $C_1$ and $C_2$. We are therefore interested in the _shared_ elements of our two events. If we draw a B or C, then we would be successful, but an A or D would be bad news for us because each is unique to a set! The *intersect operator* will help us signify this process:

$$ C_1 \cap C_2 = \{A,B,C\} \cap \{B,C,D\} = \{B,C\} 
(\#eq:intersect)$$

Unlike $\cup$, the intersect operator represents **and**. That is to say, if we are interested in the occurrence of one event AND another (a.k.a., our sample landing in both events), then the intersect is used. This operator can create some interesting conundrums, so it's worthwhile to do another example or two. This time let's define our sets to be $C_1 = \{A,B\}$ and $C_2 = \{C,D\}$. Now we're interested in whether or not our sample falls in $C_1$ and $C_2$ (What do you think is going to happen here?):

$$ C_1 \cap C_2 = \{A, B\} \cap \{C, D\} = \{\} $$

Wow, that was an interesting result! Our two sets had no overlap. You couldn't possibly draw a single element that landed in _both_ the sets, and as a result, we get a very special set - the *null set* - $\{\}$. The null set is the set with zero elements, and it is a member of every set. It's fun and interesting to see how it works with our operators. For example:

$$ \{A,B,C,D,E\} \cap \{\} = \{\} $$ 

The null set intersected with any other set is itself. A set with something in it can share nothing with a set that has no elements at all. In a way, intersecting the empty set with any other set is like multiplying a number by zero. Next, what do you suppose happens when we union the null set with something else? Let's try it out:

$$ \{A,B,C,D,E\} \cup \{\} = \{A,B,C,D,E\} $$

A set unioned with the null set is itself. The null set has nothing unique to add to our something set. Although the null set is really cool (in my opinion; and I hope your opinion too), working with it is (metaphorically speaking) like talking to the most boring person in the world. You have nothing in common with them ($\cap$), and they have nothing to add ($\cup$). And, with that, you have learned your first set theory insult.

Up to this point, we've learned how to describe our sample space, the concept of an event, how to create new events with union/intersect (or/and) operators, and the fancy null set. That's about all we need. I would like to finish out this brief section on sets with a discussion of the *complement* of a subset and a brief treatment of how the previously mentioned operators work in the continuous case.

The complement of a subset describes all the elements of a sample space _not_ in that subset. For the sake of consistency, we'll keep using our sample space $S$, and let's work with $Y = \{A,B,C\}$ and $Y\subset S$ . The complement of that subset in the sample space would be $\{D, E\}$. The operation of taking the complement of a subset is indicated by:

$$ Y^c = \{A,B,C\}^c = \{D,E\} 
(\#eq:complement)$$

The complement allows for a wider breadth of operations. Let's again consider our sample space $S$ \@ref(eq:discreteset). Suppose we were interested in an event that was NOT in the two subsets $C_1 = \{A,B\}$ or $C_2 =\{C,D\}$. The first thing we would do in this circumstance is maybe consider all the ways our sample could be unsuccessful (we won't us "fail" here; too negative). It would be unsuccessful if it landed in $C_1$ or $C_2$. Recall that the $\cup$ (union) gives us the unique elements in both sets. Let's take these two sets and union them into a set $X$ together.

$$ C_1 \cup C_2 = \{A,B,C,D\} = X $$

Now that we have our subset of unsuccessful elements, we just take the complement of that:

$$ X^c = \{E\} $$
Of course, you might have known the answer to this all along, but it's nice to see the steps broken down exactly. You could have written it all in one go using parentheses to specify order of operations, e.g.:

$$ (C_1 \cup C_2)^c = \{A, B, C, D\}^c = \{E\} $$

Notice how we do the operation in the parentheses before taking the complement. Let's try one more example with $C_1$ and $C_2$. Let's say we defined a successful sample as all the things NOT in C_1 and C_2. Notice the key word "and". Our list of unsuccessful items will be different this time because we are referring to the shared (intersect) of both our subsets. Therefore:

$$ (C_1 \cap C_2)^c = \{\}^c = \{A,B,C,D,E\} $$

The two sets have no overlap, so their intersect is the null set, and the complement of the null set is all the elements in our sample space. Fun!

With a good understanding of some of the basic operators and sets, let's turn to a brief treatment of the continuous sample space. The continuous case is very similar to the discrete case - although it takes some drawing of number lines if you are rusty with inequalities (no problem). Suppose we are sampling from a sample space $S = \{x\,|\,0 \leq x \leq 10 \}$ and we are interested in if the event lands in $C_1 = \{x\,|\,0 \leq x \leq 2 \}$ OR $C_2 = \{x\,|\,2 \leq x \leq 5 \}$. A successful sample here would occur if our sample landed anywhere from zero to five. In other words:

$$ \{0 \leq x \leq 2 \}\:\cup\:\{2 \leq x \leq 5\} = \{0 \leq x \leq 5\} $$