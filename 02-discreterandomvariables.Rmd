# Discrete Random Variables
As behavioral researchers, we are often studying a population of something. We might be interested in the percentage of individuals who like cats or the number of cats owned by the average individual. We might be interested in the average happiness level of a population of individuals and/or what makes them happy. The populations we study are often vaguely defined, e.g. as in the population of people who have received some experimental treatment. In this chapter, we will begin to take these somewhat vague notions and make them concrete. Here we shall talk about the discrete sample space and probabilities therein. 

As usual, it will be useful to start this discussion with an example. When we are in the process of conducting quantitative research (and statistics), we measure things in numbers. You may have noticed that our previous discussions of discrete sample spaces used non-numeric descriptions - e.g. $S = \{H, T\}$ in the case of a coin flip, etc. In practice, we shall map the values in a discrete sample space to numbers. This makes them easier to work with and describe. In the case of a coin, we might map heads to 1 and tails to 0. Our set of outcomes would then be described as $S = \{1,0\}$. On a given random experiment within this space, the outcome may therefore be a 1 or 0. 

What we have just described in is a *discrete random variable* - a variable that assumes a _number_ as a result of randomness. The numbers that the random variable can take are called the _space_ of the random variable. Like the discrete sample space, the outcomes in the space of a discrete random variable are either finite or countable. Oftentimes, discrete random variables - and random variables more generally - are referred to by the capital letter $X$. This variable will assume an outcome at the resolution of some random process, and a potential _outcome_ of this randomness is referred to by a lower case $x$. 

Recall in the last chapter, we discussed the probability set operator - $P()$. This operator assigns the probability to an outcome - in this case $x$ - on the basis of a set of rules. The set of rules that map an outcome to a probability is referred to as a probability distribution. Specifically, the probability distribution for a discrete random variable is called a *probability mass function* - $p(x)$ - where $x$ is a particular outcome in the space of $X$.

Suppose we are looking to assign a probability to some value of $x$ - let's say $\{x|X = x\}$ where $x$ is some value in the space of $X$. As before we might write, $P(\{x|X = x\})$, but that's a pain, so we will use the shorthand $P(X = x)$. The set of rules the probability set operator uses (a.k.a, a probability distribution) can be described like this:

$$
P(X=x) = p(x) = 
\begin{cases}
\frac{1}{2} & x = 1 \\
\frac{1}{2} & x = 0
\end{cases}
$$
Note that $P(X = x)$ and $p(x)$ mean the same thing - hence the equal sign. After the large curly-brace, you will see a row for each outcome in the space of $X$. For example, $P(X = 1) = p(1) = 1/2$. The values of x for which $p(x) > 0$ are called the support of $X$.


