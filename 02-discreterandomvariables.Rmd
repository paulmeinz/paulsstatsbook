# Discrete Random Variables
As behavioral researchers, we are often studying a population of something. We might be interested in the percentage of individuals who like cats or the number of cats owned by the average individual. We might be interested in the average happiness level of a population of individuals and/or what makes them happy. The populations we study are often vaguely defined, e.g., as in the population of people who have received some experimental treatment. Here, we will begin to take these somewhat vague notions and make them concrete. It turns out that, when we are studying a population, we are really studying what statisticians call a **random variable**. In this chapter, we will pay particular attention to the **discrete random variable**.

## What is a discrete random variable?

When we are in the process of conducting quantitative research (and statistics), we measure things in numbers. You may have noticed that our previous discussions of discrete sample spaces used non-numeric descriptions - e.g., $S = \{H, T\}$ in the case of a coin flip. In practice, we shall map the values in a discrete sample space to numbers. This makes them easier to work with and describe. Moving back to our frequently referenced example of a coin flip, we might map heads to the value of 1 and tails to the value of 0. Our set of outcomes would then be described as $\{1,0\}$. On a given random experiment within this space, we may therefore get a 1 or 0 at the resolution of our draw or random process.

Indeed, what we have just described is known as a **discrete random variable** - a variable that assumes a _number_ as a result of some random process (e.g., a random experiment, drawing out of a hat, rolling, randomly sampling, etc.). The set of possible numbers for a given discrete random variable is called the _space_ of the random variable, and like the discrete sample space, these outcomes shall be either finite or countable. In general we refer to a random variable with a capital letter, typically $X$. To avoid ambiguity, a potential _outcome_ of this random variable is referred to symbolically by a lower case letter, e.g., $x$. 

We shall refer to events in the space of $X$ using a simplified set notation. Suppose we are describing the set of outcomes where our random variable $X$ attains a value of 1. For the sake of simplicity, we will use the shorthand, $X = 1$, or more generally, $X = x$. We may also use an inequality - e.g., $X \leq x$ - to reference a range of outcomes. This shorter form is used frequently within the field of statistics and probability, so it's good to learn it now before we move into the more interesting stuff.  

Because $X$ is a random variable, we shall need a concrete way of describing it's randomness. Recall in the last chapter, we discussed the probability set operator - $P()$. This operator assigns the probability to an outcome - $x$ - on the basis of a set of rules. As we noted, the set of rules for the assignment of probability is called a probability distribution, and in the case of a discrete random variable, this distribution is called a **probability mass function** (pmf) - $p(x)$. Note that $x$ is used to reference a particular numeric outcome in the space of $X$. The set of rules (a.k.a, a probability mass function) are frequently described like this:

$$
P(X=x) = p(x) = 
\begin{cases}
\frac{1}{2} & x = 1 \\
\frac{1}{2} & x = 0
\end{cases}
$$

Note that $P(X = x)$ and $p(x)$ mean the same thing - hence the equal sign. After the large curly-brace, you will see a row for each outcome in the space of $X$. In that row you will find the probability for that outcome. For example, $P(X = 1) = p(1) = 1/2$. The pmf of $X$ has two important properties. Specifically:

1. All the outcomes $x$ in the space of $X$ have a probability $0 \leq p(x) \leq 1$. That is, all the outcomes in the space of $X$ must have a probability from 0 to 1. The set of outcomes for which $p(x) > 0$ is called the **support** of $X$.

2. Given the space $S$ of a random variable, $P(S)$ = 1. In other words, if we are conducting a random experiment by drawing a value from the space of $X$ (the set of all numeric outcomes for $X$), the probability that it lands in $S$ is 1. This hearkens back to \@ref(eq:setprop) in the previous section.

In plain language these two properties mean that we can define the pmf of a random variable by taking a total of one unit of probability and spreading it across a set of outcomes (the support of $X$). For example, you might give .25 probability to a value of 1, .5 to a value of 2, and .25 to a value of 3. In this case, each outcome would have a probability from 0 to 1, and these values would sum to 1. 

In this chapter we will dig into discrete random variables in three steps:

1. We shall start by discussing the independence of random variables - with the goal of framing an intuition for the concept.

2. We will then turn our attention to things researchers might want to know about discrete random variables (and, as you will learn, random variables more generally).

3. And finally, we will discuss some random variables that are frequently found in behavioral research.

## Independence of discrete random variables
The concept of independence is found frequently within the field of statistics. As you read on, you will find that it is essential to the derivation, understanding, and validity of some of the most fundamental things we shall learn in statistics. Therefore, it is nice to have a deeper understanding of it. The goal of this section is to frame an intuition of the independence of random variables. A deeper mathematical understanding shall be saved for your inevitable foray into mathematical statistics (no doubt after being inspired by this book to master the topic).

In the last chapter, we discussed the concept of the independence of _events_ in a random experiment. We shall now discuss independence as it pertains to random variables. And, as you will see, it is very similar to the concept of independence for events. Suppose we have two random variables $X_1$ and $X_2$. Then we say the two variables are independent if

$$
P(X_1 = x_1 \cap X_2 = x_2) = P(X_1 = x_1)P(X_2 = x_2)
(\#eq:descreteind)
$$
In other words, if two random variables are independent, the probability of $X_1 = x_1$ AND $X_2 = x_2$ is equal to the product of their respective probabilities. We've already seen examples of this. Recall in example \@ref(exm:coins), we flipped three coins _independently_. If we mapped the outcomes of each coin to 1 and 0 for heads and tails, respectively, then the three resulting random variables are independent in the sense of \@ref(eq:descreteind).

With some algebraic manipulation of \@ref(eq:descreteind), we can see that the definition of independence for random variables is very similar to the definition of independence for events

$$
\frac{P(X_1 = x_1 \cap X_2 = x_2)}{P(X_2 = x_2)}=P(X_1 = x_1)
(\#eq:descreteind2)
$$
And, perhaps not surprisingly, if the two random variables are not independent then

$$
\frac{P(X_1 = x_1 \cap X_2 = x_2)}{P(X_2 = x_2)} = P(X_1 = x_1|X_2 = x_2) \neq P(X_1 = x_1)
$$
Put into (more understandable) words, when two random variables are dependent, an event in the space of one variable _changes_ the probability of an event in the space of another variable. This may seem a bit confusing at first, but you have already seen an example of the dependence of random variables in the last chapter. Recall example \@ref(exm:dice), when we looked at the sum of two dice. In this case, let's call the sum of our two dice the random variable $Z$ and represent the random variable of the first die by $X$. 

On the basis of \@ref(eq:descreteind), we shall be looking to determine if

$$
\frac{P(Z = z \cap X = x)}{P(X = x)} \neq P(Z = z)
$$

The first thing we will need is $P(Z = z)$. The space of $Z$ are all the possible sums of our two dice - $\{2,3,4,5,6,7,8\}$. Using the table we created in example \@ref(exm:dice), and the law of addition, we can determine a probability distribution for $Z$ (try it yourself and see if you get the same thing as below)

$$
P(Z=z) = p(z) = 
\begin{cases}
1/16 & z = 2 \\
2/16 & z = 3 \\
3/16 & z = 4 \\
4/16 & z = 5 \\
3/16 & z = 6 \\
2/16 & z = 7 \\
1/16 & z = 8
\end{cases}
$$

After our computation, we can see that the most probable value is 5. Because we haven't had much experience with random variables, it is also important to point out that this distribution has all our previously discussed properties of a pmf. The probabilities of all the outcomes in the space of $Z$ sum to 1, and they are constrained between 0 and 1. 

Now that we have determined the probability mass function for $Z$, we shall calculate $(P(Z = z|X = x))$. Hopefully the idea of independence/dependence of random variables will come into focus. Consider the case where $X = 1$ (a 1 was rolled on the first die). What does the distribution of $P(Z = z|X = 1)$ look like? To determine this we shall calculate the conditional probability of each Z - _given_ our first dice roll is a 1. We did this back in example \@ref(exm:dice) for the specific value of $Z = 3$, and now we shall do it here for every value (try it yourself)

$$
P(Z=z|X=1) = p(z|x=1) = 
\begin{cases}
1/4 & z = 2 \\
1/4 & z = 3 \\
1/4 & z = 4 \\
1/4 & z = 5 \\
0 & z = 6 \\
0 & z = 7 \\
0 & z = 8
\end{cases}
$$

Do you see what happens with the event $X = 1$? The probability of $Z$ _changes_ with a roll of a 1 on the first die. For example, getting a $Z = 2$ now has a whopping 1/4 chance, compared to a paltry 1/16 before the first dice was rolled. Moreover, the probability is now spread across only four values - $\{2,3,4,5\}$. That is, the support of $Z$ - given $X = 1$ - is now 2, 3, 4, and 5. Thus, an intuitive definition of independence pivots on changes in the pmf of one random variable given the outcome of another variable. 

This idea of independence shall be sufficient for our purposes, especially as we become more sophisticated in statistics and statistical analysis. As you will see, some of the most fundamental statistical concepts require an _assumption_ of independence. In many cases, we shall assume that our random variables are independent to take advantage of some convenient mathematical properties associated with independence. We'll see one of these convenient properties as soon as the next section.

## What do we want to know about discrete random variables?
A new statistics student will have made it to this point and reasonably wondered: what the heck is the point of all this back story? This skepticism is understandable, welcomed, and hopefully motivating. In this section, we shall discuss some things - as statisticians and researchers - that we might want to know about random variables. In doing so, hopefully the bigger picture comes into view. This, in my humble opinion, is where things really start to get interesting. I'm hoping you feel the same. 

But first, let's do a very very short review.

### A very quick review: The summation operator
As statisticians we will need to sum a lot of things. It will therefore be useful to have an easy way to describe the operation of summation. To that end, suppose we are summing a set of numbers

$$
x_1 + x_2 + x_3 + x_4 + x_5 \,+\:... + x_n
$$

The **summation operator** helps us write this operation more efficiently and with less ambiguity:

$$
\sum_{i=1}^{n} x_i
(\#eq:summation)
$$
The $i$ at the bottom of the $\sum{}^{}$ is referred to as the _index_. The index is how we refer to a single element in our set of $x$'s. For example, $i=5$ refers to $x_5$. The starting index is specified at the bottom of the summation operator to the right of the equal sign. In the equation above we are starting at the 1st element of our set of $x$'s. The value at the top of the summation operator is the index of the last element to be summed. Here we have written $n$ which is the last element of our set of n $x$'s. In other words

$$
\sum_{i=1}^{n} x_i = x_1 + x_2 + x_3 + x_4 + x_5 + ... + x_n
$$
in terms of our example above. Additionally, it is important to note that n and i are not always used to indicate the last element and the index, respectively. Here we shall try to be consistent. Occasionally, to save a little time we shall write the summation operator like

$$
\sum_{x}^{}
$$

This means - given all the $x's$ in a set - sum all of them. Alright, now it's time for the interesting stuff.

### The expectation of a discrete random variable
The first thing that we shall want to know about a discrete random variable is its expectation. Given a random variable $X$, we refer to its expectation as $E(X)$. We shall also sometimes refer to it algebraically as $\mu$. In other words

$$
E(X) = \mu
$$

The expectation is commonly referred to as the **mean** of a random variable. The expectation of a random variable $X$ with a given pmf - $p(x)$ is calculated 

$$
E(X) = \sum_{i = 1}^{n} x_ip(x_i)
(\#eq:discreteexpectation)
$$

In words: For each $x$ in the space of $X$, multiply by its corresponding probability and sum the resulting values. An example, will help us understand the expectation a bit better.

::: {.example #ogexpectation} 
Suppose we have a random variable $X$ with five outcomes in it's space - $\{1,2,3,4,5\}$. Further assume that the pmf of $X$ assigns $\frac{1}{5}$ probability to each outcome. 

$$
P(X=x) = p(x) = 
\begin{cases}
1/5 & x_1 = 1 \\
1/5 & x_2 = 2 \\
1/5 & x_3 = 3 \\
1/5 & x_4 = 4 \\
1/5 & x_5 = 5 
\end{cases}
$$
This is an example of a **discrete uniform distribution**. Given n outcomes, the discrete uniform distribution assigns $1/n$ probability to each outcome on the space of the random variable.

Now let's calculate the expectation of this random variable.

$$
\begin{align}
E(X) = \sum_{i=1}^{5} x_ip(x_i) &= x_1p(x_1)+x_2p(x_2)+x_3p(x_3)+x_4p(x_4)+5p(x_5) \\
&= 1p(1)+2p(2)+3p(3)+4p(4)+5p(5) \\
&= (1)\frac{1}{5}+(2)\frac{1}{5}+(3)\frac{1}{5}+(4)\frac{1}{5}+(5)\frac{1}{5} \\
&= \frac{15}{5} = 3
\end{align}
$$
We've multiplied each value in the space of our random variable $X$ by its probability and summed the values. The result of our computation is 3 - $E(x) = 3$ - but what does that mean exactly? Well let's explore the idea of expectation further by plotting the pmf of $X$. In the figure below, the probability of each outcome is plotted. You can see the outcomes of the random variable labelled on the $x$ axis, and probability of each is represented by the bar height. In this case, each outcome is equally likely, so the bars are of equal height.  

```{r, echo = FALSE}
a <- data.frame(x = c(1,2,3,4,5), 
                y = rep(1/5, times = 5))
                

ggplot2::ggplot(a, ggplot2::aes(x = x, y = y)) +
  ggplot2::geom_col(fill = 'gray', color = 'black') +
  ggplot2::scale_y_continuous(limits = c(0,1)) +
  ggplot2::theme(panel.grid.major = ggplot2::element_blank(),
                 panel.grid.minor = ggplot2::element_blank()) +
  ggplot2::labs(x = 'Outcome', y = 'Probability Mass') +
  ggplot2::geom_vline(xintercept = 3)


```
Now suppose each of those bars has _mass_ (a.k.a. probability mass), and further suppose we'll place our wedge under the $x$ axis such that the mass of the plot balances perfectly. Just by looking at the plot, if we put a wedge directly under the value of 3, there would be equivalent probability mass on either side, and the plot would balance perfectly. Indeed, the number 3 was the result of our computation above. The expectation can therefore be thought as the balancing point of the plot - the place that would perfectly balance the mass of probability for our random variable.
:::

Hopefully that example helped build an initial understanding of the expectation. We shall need to learn a little bit more about the expectation to proceed on our statistical adventure. First let's observe that it is possible to take the expectation of some _function_ of a random variable. In other words, we may apply some function to the outcomes in the space of $X$ and then calculate an expectation. For example, we might have

$$
f(X) = 2X
$$
This function takes the outcomes in the space of $X$ and multiplies each by 2. We shall calculate the expectation of this function of our random variable by 

$$
E(f(X)) = \sum_{i = 1}^{n} f(x_i)p(x_i)
(\#eq:discreteexpectationfunction)
$$

Let's try it out in a couple examples.

::: {.example #exp1}
We will again use the distribution from example \@ref(exm:ogexpectation). Here we will keep it simple (and also demonstrate a property of multiplication you may recall from algebra). Suppose our function $f(x)$ takes every value in the space of $X$ and returns the value one. In other words,

$$
f(X) = 1
$$
Let's apply \@ref(eq:discreteexpectationfunction) to find the expectation of this function. First, let's remind ourselves of the distribution of $X$ and calculate $f(x)$ for each outcome in it's space

$$
p(x) =
\begin{cases}
1/5 & x_1 = 1 & f(1) = 1 \\
1/5 & x_2 = 2 & f(2) = 1 \\
1/5 & x_3 = 3 & f(3) = 1 \\
1/5 & x_4 = 4 & f(4) = 1 \\
1/5 & x_5 = 5 & f(5) = 1 
\end{cases}
$$
Now let's calculate the expectation of $f(X)$. Watch the underlined values for a little bit of algebra review.

$$
\begin{align}
E(X) = \sum_{i=1}^{5} f(x_i)p(x_i) &= \underline{1}\:p(x_1)+\underline{1}\:p(x_2)+\underline{1}\:p(x_3)+\underline{1}\:p(x_4)+\underline{1}\:p(x_5) \\
&= \underline{1}\:[p(x_1) + p(x_2) + p(x_3) + p(x_4) + p(x_5)] \\
&= \underline{1}\:[\frac{1}{5} + \frac{1}{5} + \frac{1}{5} + \frac{1}{5} + \frac{1}{5}] \\
&= \underline{1}(1) = 1
\end{align}
$$
The second line of this calculation was made possible by the distributive property of multiplication. That made the computation easier because we note that the sum of probabilities over the space of $X$ is equal to 1 (see the third line; and see the properties of a discrete random variable at the start of this chapter).
:::

::: {.example #exp2}
Suppose our random variable $X$ is again defined as in example \@ref(exm:ogexpectation). Now let's use the function $f(x)= 2X$. Then let's again apply the function to the space of $X$ 
$$
p(x) = 
\begin{cases}
1/5 & x_1 = 1 & f(1) = 2(1) = 2 \\
1/5 & x_2 = 2 & f(2) = 2(2) = 4 \\
1/5 & x_3 = 3 & f(3) = 2(3) = 6 \\
1/5 & x_4 = 4 & f(4) = 2(4) = 8 \\
1/5 & x_5 = 5 & f(5) = 2(5) = 10 
\end{cases}
$$

$$
\begin{align}
E(2X) = \sum_{i=1}^{5} f(x_i)p(x_i) &= 2p(x_1)+4p(x_2)+6p(x_3)+8p(x_4)+10p(x_5) \\
&= (2)\frac{1}{5} + (4)\frac{1}{5} + (6)\frac{1}{5} + (8)\frac{1}{5} + (10)\frac{1}{5} \\
&= \frac{30}{5} = 6
\end{align}
$$
:::

The astute observer might notice an interesting trend in the last two examples. In example \@ref(exm:exp1), we saw that our function which converts the whole space of $X$ into 1 had the expectation of 1. Indeed, looking back at the computation, we could perform that computation for any constant, e.g., if $a$ is a constant, and $f(X) = a$, then

$$
\begin{align}
E(a) = \sum_{i=1}^{5} ap(x_i) &= \underline{a}\:p(x_1)+\underline{a}\:p(x_2)+\underline{a}\:p(x_3)+\underline{a}\:p(x_4)+\underline{a}\:p(x_5) \\
&= \underline{a}\:[p(x_1) + p(x_2) + p(x_3) + p(x_4) + p(x_5)] \\
&= \underline{a}\:[\frac{1}{5} + \frac{1}{5} + \frac{1}{5} + \frac{1}{5} + \frac{1}{5}] \\
&= \underline{a}(1) = a
\end{align}
$$

In other words, we would get the value of our constant every time. Similarly, in \@ref(exm:exp2), recall that the original expectation of $X$ was 3. Our function $f(X) = 2X$ had the expectation of $2\times3 = 6$. That is, we multiplied $X$ by 2 and got back 2 times its expectation.

Our last two observations highlight a couple of _properties_ of the expectation. We'll list a few below. The first two (or three) you might have deduced yourself. The second two are new, and we'll pay particular attention to the fourth.

::: {.theorem #expprop name="Some Properties of the Expectation"}
If a and b are constants, then

1. E(b) = b

2. E(aX) = aE(X)

3. More generally, E(aX + b) = aE(X) + b

If $X_1$ and $X_2$ are random variables, then 

4. $E(aX_1 + bX_2)$ = $aE(X_1) + bE(X_2)$
:::

These are called properties because they apply to any random variable - assuming that random variable has an expectation (a more advanced topic that we won't discuss in much depth in this book). They allow us to perform computations with expectations without knowing much about the actual distribution of the random variable. And, they make computations easier. As you will see later, they will help us draw certain conclusions about the populations we study. For now, let's see how they work in practice and look at a more thorough example for the fourth.

::: {.example}
Suppose we are given a random variable - $Z$ - and $E(Z)$ = 7
:::
