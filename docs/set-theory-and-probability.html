<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Set Theory and Probability | Behavioral Statistics: Theory and Application</title>
  <meta name="description" content="<p>This is a behavioral statistics textbook with additional mathematical depth
that I wish I had had prior to enrolling in my first graduate level behavior
statistics course.|</p>" />
  <meta name="generator" content="bookdown 0.45 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Set Theory and Probability | Behavioral Statistics: Theory and Application" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="<p>This is a behavioral statistics textbook with additional mathematical depth
that I wish I had had prior to enrolling in my first graduate level behavior
statistics course.|</p>" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Set Theory and Probability | Behavioral Statistics: Theory and Application" />
  
  <meta name="twitter:description" content="<p>This is a behavioral statistics textbook with additional mathematical depth
that I wish I had had prior to enrolling in my first graduate level behavior
statistics course.|</p>" />
  

<meta name="author" content="Paul Meinz, Ph.D" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Advanced Behavioral Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#you-can-learn-statistics"><i class="fa fa-check"></i><b>1.1</b> You can learn statistics</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#why-i-wrote-this-book"><i class="fa fa-check"></i><b>1.2</b> Why I wrote this book</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#what-content-to-expect-in-this-book"><i class="fa fa-check"></i><b>1.3</b> What content to expect in this book</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#what-youll-need-to-know-to-get-the-most-out-of-this-book"><i class="fa fa-check"></i><b>1.4</b> What you’ll need to know to get the most out of this book</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#future-editions-of-this-book"><i class="fa fa-check"></i><b>1.5</b> Future editions of this book</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="set-theory-and-probability.html"><a href="set-theory-and-probability.html"><i class="fa fa-check"></i><b>2</b> Set Theory and Probability</a>
<ul>
<li class="chapter" data-level="2.1" data-path="set-theory-and-probability.html"><a href="set-theory-and-probability.html#sets-and-sample-spaces"><i class="fa fa-check"></i><b>2.1</b> Sets and Sample Spaces</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="set-theory-and-probability.html"><a href="set-theory-and-probability.html#repeated-samples"><i class="fa fa-check"></i><b>2.1.1</b> Repeated Samples</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="set-theory-and-probability.html"><a href="set-theory-and-probability.html#what-is-probability"><i class="fa fa-check"></i><b>2.2</b> What is probability?</a></li>
<li class="chapter" data-level="2.3" data-path="set-theory-and-probability.html"><a href="set-theory-and-probability.html#conditional-probability-and-independence"><i class="fa fa-check"></i><b>2.3</b> Conditional Probability and Independence</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Behavioral Statistics: Theory and Application</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="set-theory-and-probability" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapter 2</span> Set Theory and Probability<a href="set-theory-and-probability.html#set-theory-and-probability" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In the course of research, behavioral scientists will often take samples of human behavior, e.g. a survey of a group of people, measurements of reaction time, etc. These samples will take some <em>outcome</em>, and most of us understand and have observed the inherent randomness of this act. That is to say, you might take the exact same sample in a carefully controlled circumstance and get different results every time.</p>
<p>Statisticians often refer to an analogous circumstance when talking about probability. Suppose we are able to describe all the possible outcomes of our sampling procedure. We take samples over and over again in the same circumstances, and each time the outcome may change. This is referred to as a <strong>random experiment</strong>. In order to familiarize you with some introductory concepts around probability, we’re going to start in this context of a random experiment. First, we’ll learn about sets and set theory in order to describe our <strong>sample space</strong>. This will also be useful in describing the form that outcomes of a random experiment may take. Then we’ll more concretely define the randomness of our experiment by talking about <strong>probability</strong> - the quantification of randomness.</p>
<div id="sets-and-sample-spaces" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Sets and Sample Spaces<a href="set-theory-and-probability.html#sets-and-sample-spaces" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Before we get into it, we aren’t going to learn set theory in it’s entirety. That would be overly (and hilariously) ambitious. What we are going to learn will make understanding later sections easier, get your brain warmed up, and make it a bit easier to understand set notation in other circumstances. The first step in conducting a random experiment is clearly defining all the possible outcomes of your sampling procedure. This is referred to as the <strong>sample space</strong>. Suppose we have five different possible outcomes in our sample space: A, B, C, D, and E. Let’s call this sample space <span class="math inline">\(S\)</span>. Then we would describe it like this:</p>
<p><span class="math display" id="eq:discreteset">\[
S = \{A, B, C, D, E\}
\tag{2.1}
\]</span>
That is to say we’ll describe the set <span class="math inline">\(S\)</span> with curly braces, and on the inside of the curly braces, there shall be a list of <em>distinct</em> elements of our set. The sample space above is an example of a <strong>discrete</strong> sample space - meaning it either contains a finite number of elements or it is <em>countable</em>. In this case, the sample space has a finite number of elements (five to be exact), so we can call it discrete.</p>
<p>On the other hand, describing a countable, but not necessarily finite, sample space can be tricky. My hope is you can gain a small sense for it from my explanation here. We’ll see examples of it later. Specifically, a discrete sample space can also contain an <em>infinite</em> number of elements - so long as those elements can be lined up one-to-one with the natural numbers (e.g. 1, 2, 3, 4, …). That is, the elements can be “counted”, albeit infinitely and forever. This is probably not the most intuitive definition for people who don’t think about mathematics every day (it certainly wasn’t for me). In another, perhaps more reachable sense, a discrete sample space - finite or infinite - has elements with nothing in between them. In <span class="math inline">\(S\)</span> above, there is nothing in between A and B, for example. If your discrete set had an infinite number of elements, you could line them up (arbitrarily) with the natural numbers. And, after this alignment, you could find nothing between the first and second elements (or any given sequential pair for that matter). You could go one enumerating each element until the end of time.</p>
<p>With that point out of the way, we may also find ourselves sampling from a <strong>continuous</strong> sample space, e.g., all the values between and including 0 and 1 (e.g <span class="math inline">\(0 \leq x \leq 1\)</span>). Since you can’t enumerate all the values of a continuous sample space as we did with <span class="math inline">\(S\)</span> (people have “tried”; we’ll talk about one such example later), we use a different form of notation. Suppose we have a continuous sample space <span class="math inline">\(R\)</span>, then we would specify it as</p>
<p><span class="math display" id="eq:continuousset">\[
R = \{x\, | \, 0 \leq x \leq 1 \}
\tag{2.2}
\]</span></p>
<p>The inclusion criteria for the set is written after the <span class="math inline">\(|\)</span> in the curly braces. The <span class="math inline">\(|\)</span> can be read loosely as meaning “where”, so reading the whole thing in the curly braces left to right you get x <em>where</em> <span class="math inline">\(0 \leq x \leq 1\)</span>. Therefore, our set is all the <span class="math inline">\(x\)</span>’s from 0 to 1. Note that I will occasionally drop the <span class="math inline">\(x\)</span> and <span class="math inline">\(|\)</span> when it is clear what variable I am referencing. As an aside, continuous sample spaces can be found everywhere in the field of behavioral statistics. For reasons that will become apparent later, we shall nonetheless approach these spaces with slightly less mathematical depth.</p>
<p>Now, having discussed discrete and continuous sample spaces, it is time to turn our attention towards the outcome of our random experiment. Suppose we are randomly drawing a single item from our sample space <span class="math inline">\(S = \{A, B, C, D, E\}\)</span>. The <em>outcome</em> of our experiment is a single item from our sample space, and we will talk about outcomes in terms of <em>events</em>. Events are described by a <em>subset</em> of distinct elements from the sample space. That is, they may be one or more outcomes combined. For example, we might say the event is <span class="math inline">\(C = \{A, B, C\}\)</span>, and if our outcome lands in the that subset (as either A, B, or C), then we shall say the event “occurred”. For the sake of brevity, and positivity, I will referred to the occurrence of an event as a “success” (congratulations all around!). You can indicate a set is a subset by:</p>
<p><span class="math display" id="eq:subset">\[ C \subset S
\tag{2.3} \]</span></p>
<p>In this case, we are saying <span class="math inline">\(C\)</span> is a subset of <span class="math inline">\(S\)</span>. We might also, for example say that our event is a single element/outcome <span class="math inline">\(C_1 = \{A\}\)</span> or the entire sample space <span class="math inline">\(C_2 = \{A,B,C,D,E\}\)</span>. We can be as creative as we would like to be, so long as the event is in our sample space.</p>
<p>Indeed, in practice we might want to get a little more creative in terms of the outcomes of our random experiment. Let’s talk about a slightly more complicated scenario. Suppose we have two events <span class="math inline">\(C_1 = \{A,B,C\}\)</span> and <span class="math inline">\(C_2 = \{B,C,D\}\)</span>, and we are interested in whether or not our outcome lands in <span class="math inline">\(C_1\)</span> or <span class="math inline">\(C_2\)</span>. It’s helpful here to consider the circumstances where we this event would occur. Namely, If the instantiation of our outcome was an A, B, C, or D, then we would be successful (success!). That is to say, we’ve taken all the unique outcomes of either set and combined them into a new set. If our outcome lands in that new subset, we can be confident that <span class="math inline">\(C_1\)</span> or <span class="math inline">\(C_2\)</span> occurred. There’s a handy symbol that indicates this operation:</p>
<p><span class="math display" id="eq:union">\[ C_1 \cup C_2 = \{A,B,C\}\:\cup\:\{B,C,D\} = \{A,B,C,D\}
\tag{2.4} \]</span></p>
<p>This <em>union operator</em> (<span class="math inline">\(\cup\)</span>) takes the unique elements of both sets and puts them into a set of their own. In this circumstance it is used synonymously with <em>or</em>. If the event of interest is our outcome landing in <span class="math inline">\(C_1\)</span> OR <span class="math inline">\(C_2\)</span>, then we would be successful if the event landed in the union of the two sets, e.g., all the unique elements from both sets. Here’s another example, suppose we are interested in if our outcome falls into <span class="math inline">\(C_1 = \{A\}\)</span> or <span class="math inline">\(C_2 = \{B\}\)</span>. Then our event would occur if the element was A or B:</p>
<p><span class="math display">\[ \{A\}\:\cup\:\{B\} = \{A,B\} \]</span>
Our random experiment would be successful if our outcome was an A OR a B.</p>
<p>Indeed, the union operator helps us figure out the conditions for success when we are interested in the occurrence of one event OR another. Let us now turn our attention to another equally important operator. Suppose we have our two previously described events - <span class="math inline">\(C_1 = \{A,B,C\}\)</span> and <span class="math inline">\(C_2 = \{B,C,D\}\)</span> - each a subset of <span class="math inline">\(S\)</span>. Lets further say that we are interested in whether or not both events occur as a result of our random experiment. That is, we shall be successful if our outcome falls in both <span class="math inline">\(C_1\)</span> AND <span class="math inline">\(C_2\)</span>. We are therefore interested in the <em>shared</em> elements of our two events. Specifically, just by eyeballing the sets above, B and C are shared by the two events <span class="math inline">\(C_1\)</span> and <span class="math inline">\(C_2\)</span>, but if we were unfortunate enough to draw a D or an A, game over. The <em>intersect operator</em> will help us signify this process:</p>
<p><span class="math display" id="eq:intersect">\[ C_1 \cap C_2 = \{A,B,C\} \cap \{B,C,D\} = \{B,C\}
\tag{2.5}\]</span></p>
<p>Unlike <span class="math inline">\(\cup\)</span>, the intersect operator represents <strong>and</strong>. It tells us the conditions for success if we would like <em>both</em> events to occur (a.k.a., our outcome landing in both events). This operator can create some interesting conundrums, so it’s worthwhile to do another example or two. This time let’s define our events to be <span class="math inline">\(C_1 = \{A,B\}\)</span> and <span class="math inline">\(C_2 = \{C,D\}\)</span>. Now we’re interested in whether or not our outcome falls in <span class="math inline">\(C_1\)</span> and <span class="math inline">\(C_2\)</span> (What do you think is going to happen here?):</p>
<p><span class="math display">\[ C_1 \cap C_2 = \{A, B\} \cap \{C, D\} = \{\} \]</span></p>
<p>Well, you may have guessed it: Our two sets had no overlap. You couldn’t possibly draw a single element that landed in <em>both</em> the sets, because the sets share no elements. As a result, we get a very special set - a <em>null set</em> - <span class="math inline">\(\{\}\)</span> - which is a set with zero elements. In this circumstance, when the intersect of sets results in a null set (a.k.a. they have no overlap), we shall refer to them as being <strong>mutually exclusive</strong> - because the two sets do not share elements. In terms of probability, mutually exclusive sets can be much easier to work with. We’ll talk about this soon.</p>
<p>Now you have some understanding of the two main set operators we’ll need - the union (<span class="math inline">\(\cup\)</span>) and the intersect (<span class="math inline">\(\cap\)</span>). We shall need to know a little bit more about the null set, so let’s take a slightly deeper look. It’s interesting to see how a null set works with other sets that have elements. For example:</p>
<p><span class="math display">\[ \{A,B,C,D,E\} \cap \{\} = \{\} \]</span></p>
<p>A set with elements intersected with a null set is a null set. A set with something in it can share nothing with a set that has no elements at all. This is very similar to multiplying an integer by zero. In fact, when you first start writing set notation, you might be inclined to use arithmetic operators with sets, e.g., <span class="math inline">\(\{A,B,C\} - \{A,B\} = \{C\}\)</span> as opposed to <span class="math inline">\(\{A,B,C\} \cap \{A,B\} = \{C\}\)</span>. The null set and intersect gives us a handy way to multiply a set by zero without using <span class="math inline">\(\times\)</span> or 0.</p>
<p>What do you suppose happens when we union a null set with something else? Let’s try it out:</p>
<p><span class="math display">\[ \{A,B,C,D,E\} \cup \{\} = \{A,B,C,D,E\} \]</span></p>
<p>A set unioned with a null set is itself. A null set has nothing unique to add to our “something set”. Although the null set is really cool (in my opinion; and I hope your opinion too), working with it is, metaphorically speaking, like talking to the most boring person in the world. You have nothing in common with them (<span class="math inline">\(\cap\)</span>), and they have nothing to add (<span class="math inline">\(\cup\)</span>). And, with that, you have learned your first set theory insult.</p>
<p>Up to this point, we’ve learned how to describe our sample space, the concept of an outcome and event, how to create new events with union/intersect (or/and) operators, and the fancy null set. That’s about all we need. I would like to finish out this brief section on sets with a discussion of the <em>complement</em> of a subset and a brief treatment of how the previously mentioned operators work in the continuous case.</p>
<p>The complement of a subset describes all the elements of a sample space <em>not</em> in that subset. For the sake of consistency, we’ll keep using our sample space <span class="math inline">\(S\)</span> <a href="set-theory-and-probability.html#eq:discreteset">(2.1)</a>, and let’s work with <span class="math inline">\(Y = \{A,B,C\}\)</span>, <span class="math inline">\(Y\subset S\)</span>. The complement of that subset in the sample space would be <span class="math inline">\(\{D, E\}\)</span>. The operation of taking the complement of a subset is indicated by:</p>
<p><span class="math display" id="eq:complement">\[ Y^c = \{A,B,C\}^c = \{D,E\}
\tag{2.6}\]</span></p>
<p>The complement allows for a wider breadth of operations. Let’s again consider our sample space <span class="math inline">\(S\)</span>. Suppose we were interested in an event that was NOT in the two subsets <span class="math inline">\(C_1 = \{A,B\}\)</span> or <span class="math inline">\(C_2 =\{C,D\}\)</span>. The first thing we would do in this circumstance is maybe consider all the ways our outcome could be unsuccessful (we won’t use “fail” here; too negative). It would be unsuccessful if it landed in <span class="math inline">\(C_1\)</span> or <span class="math inline">\(C_2\)</span>. Recall that the <span class="math inline">\(\cup\)</span> (union) gives us the unique elements in both sets. Let’s take these two sets and union them into a set <span class="math inline">\(X\)</span> together.</p>
<p><span class="math display">\[ C_1 \cup C_2 = \{A,B,C,D\} = X \]</span></p>
<p>Now that we have our subset of unsuccessful elements, we just take the complement of that:</p>
<p><span class="math display">\[ X^c = \{E\} \]</span></p>
<p>Of course, you might have known the answer to this all along, but it’s nice to see the steps broken down exactly. You could have written it all in one go using parentheses to specify order of operations, e.g.:</p>
<p><span class="math display">\[ (C_1 \cup C_2)^c = \{A, B, C, D\}^c = \{E\} \]</span></p>
<p>Notice how we do the operation in the parentheses before taking the complement. Let’s try one more example with <span class="math inline">\(C_1\)</span> and <span class="math inline">\(C_2\)</span>. Let’s say we defined a successful outcome as all the things NOT in <span class="math inline">\(C_1\)</span> and <span class="math inline">\(C_2\)</span>. Notice the key word “and”. Our list of unsuccessful items will be different this time because we are referring to the shared (intersect) of both our subsets. Therefore:</p>
<p><span class="math display">\[ (C_1 \cap C_2)^c = \{\}^c = \{A,B,C,D,E\} \]</span></p>
<p>The two sets have no overlap, so their intersect is a null set, and the complement of the null set is all the elements in our sample space.</p>
<p>With a good understanding of some of the basic operators and sets, let’s turn to a brief treatment of the continuous sample space. The continuous case is very similar to the discrete case - although it takes some drawing of number lines if you are rusty with inequalities (no problem). Suppose we are sampling from a sample space <span class="math inline">\(S = \{x\,|\,0 \leq x \leq 10 \}\)</span> and we are interested in if the outcome lands in <span class="math inline">\(C_1 = \{x\,|\,0 \leq x \leq 2 \}\)</span> OR <span class="math inline">\(C_2 = \{x\,|\,2 \leq x \leq 5 \}\)</span>. A successful outcome here would occur if our realized element landed anywhere from zero to five. In other words:</p>
<p><span class="math display">\[ \{0 \leq x \leq 2 \}\:\cup\:\{2 \leq x \leq 5\} = \{0 \leq x \leq 5\} \]</span></p>
<p>Let’s keep the same continuous sample space and subsets as above, and this time let’s look at the intersect of the two sets:</p>
<p><span class="math display">\[ \{0 \leq x \leq 2 \}\:\cap\:\{2 \leq x \leq 5\} = \{2\} \]</span></p>
<p>The two sets only overlap at exactly <span class="math inline">\(x = 2\)</span>, so their intersect is just a set with the value 2. Let’s do a couple more so you can get a sense for it. Suppose we have a sample space <span class="math inline">\(Q = \{x\,|\, 5 \leq x \leq 10\}\)</span> and define <span class="math inline">\(C \subset Q\)</span> where <span class="math inline">\(C = \{x\,|\, 5 \leq x &lt; 7\}\)</span>. That is to say, <span class="math inline">\(C\)</span> is a subset of Q, and its interval includes the lower side (5) but it doesn’t include the upper side (7). What is the complement?</p>
<p><span class="math display">\[ C^c = \{5 \leq x &lt; 7\}^c = \{7 \leq x \leq 10\} \]</span></p>
<p>The complement includes 7 up to 10. In the plot below, you can see a visual depiction of this. The top line represents the subset <span class="math inline">\(C\)</span>, and the bottom line represents the complement. The open circle at the end of our subset <span class="math inline">\(C\)</span> indicates that the value 7 is not included in its range. The elements of C are strictly less than 7. This is in contrast to the complement line below - which has a solid black dot indicating 7’s inclusion due to its exclusion from <span class="math inline">\(C\)</span>. Thus the complement of <span class="math inline">\(C\)</span> ranges from 7 to 10.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>One more comment is worth a mention with regards to continuous sample spaces. Suppose we have two subsets of our space <span class="math inline">\(Q\)</span> that don’t overlap in any way. For example, take <span class="math inline">\(C_1 = \{x\,|\, 5 \leq x &lt; 7\}\)</span> and <span class="math inline">\(C_2 = \{x\,|\, 9 \leq x \leq 10\}\)</span>. Then you would simply write their union as:</p>
<p><span class="math display">\[ \{\, 5 \leq x &lt; 7\} \cup \{\, 9 \leq x \leq 10\}\]</span>
There is no simplified way to write this in set notation. Note the intersect of these two sets would be <span class="math inline">\(\{\}\)</span> - a null set.</p>
<div id="repeated-samples" class="section level3 hasAnchor" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Repeated Samples<a href="set-theory-and-probability.html#repeated-samples" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The previous introduction to sets was dedicated to a random experiment where we only draw a single element from our sample space. In practice, researchers and statisticians are often sampling/conducting a random experiment repeatedly. In this section we’ll talk about how to describe the sample space of an experiment that involves multiple draws. Note, for the purposes of our learning, we shall only be discussing sampling with <em>replacement</em>. That is, we will be talking about circumstances where the 1st, 2nd, 3rd, … , nth outcome gets returned to the sample space prior to the next draw. This is opposed to the circumstance where an outcome of a single sample reduces the size of the sample space each time. For example, suppose we have a sample space, <span class="math inline">\(S = \{A,B,C\}\)</span>. On our first experiment, we randomly draw an <span class="math inline">\(A\)</span>. In sampling without replacement, the sampling space for the next draw would be <span class="math inline">\(\{B,C\}\)</span> (or <span class="math inline">\(\{A\}^c)\)</span> and in sampling with replacement <span class="math inline">\(A\)</span> would be returned to the space.</p>
<p>To understand how to describe the sample spaces mentioned above, we’ll turn to a good-old-fashioned coin toss (the mainstay of every introductory probability book). Suppose we perform a single flip (experiment) from a fair coin. Our sample space would be <span class="math inline">\(S = \{H, T\}\)</span> where <span class="math inline">\(H\)</span> is “heads”, and <span class="math inline">\(T\)</span> is “tails”. Now let’s suppose we flip two counts. The sample space would be all the possible permutations of heads and tails from the two flips. It helps to draw draw a <em>tree diagram</em> to get the gist of it.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>You can follow the branches of the tree above to see each possible permutation of the two flips. For example, suppose the first flip was heads, you would follow the line at the first node (on the left) up the the “H” (heads) node. Then at the “heads” node, the next flip could either be an “H” (heads) or a “T” (tails), corresponding to the top and second from the top nodes on the right. Going down each branch, top-to-bottom, we get all the possible permutations of our two flips - <span class="math inline">\(\{HH,HT,TH,TT\}\)</span>. Our random experiment is now a selection from this new sample space.</p>
<p>Drawing a tree to determine all the permutations of multiple draws, could get quite cumbersome, so it’s convenient to have a formula. In the example above, the first flip could take 2 outcomes. The second flip would then result in two additional branches for each of the outcomes of the first flip. In other words, we have <span class="math inline">\(2 \times 2 = 4\)</span> possible permutations for the two coins. Had we flipped a third coin, each of nodes for the second flip would then be accompanied by two branches per node, so the calculation would be <span class="math inline">\(2 \times 2 \times 2 = 8\)</span> permutations. Indeed, given a sample space that has <span class="math inline">\(N\)</span> total elements/outcomes and <span class="math inline">\(k\)</span> repeated samples, all the possible permutations would be given by:</p>
<p><span class="math display" id="eq:permutations">\[ N^k
\tag{2.7}\]</span></p>
<p>Note: If we had sampled from several sample spaces, all with a different number of elements, then then we would just multiply the respective element lengths together.</p>
<p>I will end this section with an important discussion on notation. As you can see from <a href="set-theory-and-probability.html#eq:permutations">(2.7)</a>, the sample space can grow quite rapidly. For example, four coin flips would have a sample space of 16 elements. Consider the two coin sample space - <span class="math inline">\(\{HH,HT,TH,TT\}\)</span>. The event of getting a head on the first flip can be described by all the coin flip combinations with heads on the first flip - <span class="math inline">\(\{HH,HT\}\)</span>. If our random experiment and outcome fell into this subset, we would indeed have flipped a heads on the first coin. Now consider a circumstance where the sample space is much larger (e.g. 10 coins), it would become quickly untenable to write out all the possible permutations. Instead in some circumstances I may use some short hand like <span class="math inline">\(\{H \: on \: 1st \: flip\}\)</span>, because I don’t have the rest of my natural born life to list permutations (and you don’t have the rest of your natural born life to read them). Rest assured that these are exactly equivalent, and they shall be associated with the exact same probabilities. Indeed, sometimes the short hand will make it more clear as to what probability we are referring to.</p>
</div>
</div>
<div id="what-is-probability" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> What is probability?<a href="set-theory-and-probability.html#what-is-probability" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Many of us have an internal sense of this stuff we call probability. In the crisp fall of the California foothills (which is about the time that I’m writing this section), you can ask a local of Placerville how often the apple orchards get overwhelmed with tourists. More often than not, they will give you some percentage of the time, and this time of the year that percentage will undoubtedly be 100%. You might ask a Sacramento resident how confident they are in their local basketball team winning, and indeed, they may also provide you with something close to a percentage of time (my guess is 15%). The two preceding scenarios are examples of the <strong>relative frequency approach</strong> to probability. In this approach, you can think of probability in the random experiment sense. That is, if we did a random experiment over and over again, we might expect some event to occur a percentage of the time. We shall call this percentage a probability. Within this approach, probabilities can take values anywhere from <span class="math inline">\(0\leq x\leq1\)</span>. Indeed a “percentage of time” greater than 1 or less than zero would be nonsensical.</p>
<p>In the last section we discussed how we might describe sample spaces, outcomes, and events of random experiments. In this section we’ll assign probabilities to them, and we shall adopt the above relative frequency approach interpretation. Suppose we have some event <span class="math inline">\(C\)</span>, then the <strong>probability set operator</strong> - <span class="math inline">\(P()\)</span> - takes <span class="math inline">\(C\)</span>, and based on a set of rules, returns a probability for that event. The set of rules for the assignment of probability is referred to as a <strong>probability distribution</strong>. We’ll talk about probability distributions in the next chapter, but for now we’ll just focus on probability and the probability set operator. Calculating probabilities for the continuous sample space can be tricky, so we’ll stick with the discrete case and talk about the continuous later.</p>
<p>Consider for a moment the circumstance at the end of last section, flipping two fair coins. If you recall, our sample space was <span class="math inline">\(S = \{HH,HT,TH,TT\}\)</span>. Suppose the probability set operator assigns a probability of 1/4 to each of the outcomes in this sample space. The probability, for example, of the event <span class="math inline">\(C = \{HH\}\)</span> would therefore be</p>
<p><span class="math display">\[ P(C) = P(\{HH\}) = 1/4 \]</span></p>
<p>Within the relative frequency approach to probability, this means that over many many random experiments, we might see that about 25% of the outcomes are HH. This framing is meant to be an intuitive one - to give you a sense of this stuff called probability. When I have taught this to my colleagues and students, many will point out that they have flipped two fair coins a large number of times and didn’t get exactly 25% of outcomes landing HH (budding statisticians!). For our purposes, we’ll let <em>about</em> and <em>might</em> be the operative words. We may get <em>about</em> 25% double heads.</p>
<p>Let’s now turn our attention to a slightly more complex example. We’ll stick with fair coins for now. Suppose we wanted to know the probability of getting a heads on the first flip - <span class="math inline">\(C = \{HH,HT\}\)</span> - how does the probability set operator go about assigning probabilities to an event with more than one outcome? Well, lucky for us, there is the <em>law of addition</em> for probability. For two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> for which <span class="math inline">\(A \cap B = \{\}\)</span> (e.g. they are mutually exclusive):</p>
<p><span class="math display" id="eq:addlaw">\[ P(A \cup B) = P(A) + P(B)
\tag{2.8}\]</span></p>
<p>I sometimes refer to this law as the “law of or”, because it helps calculate the probability of success if we want our outcome to land in one event OR another event. So how does this law apply to our single event <span class="math inline">\(C\)</span> above? Well, recall from our earlier, we said that an event contains a set of <em>distinct</em> elements from the sample space. Because of this, every event can just be written as a union of mutually exclusive events. In our case,</p>
<p><span class="math display">\[ C = \{HH,HT\} = \{HH\} \cup \{HT\} \]</span></p>
<p>And with this in mind, we can apply the law of addition:</p>
<p><span class="math display">\[ P(\{HH\} \cup \{HT\}) = P(\{HH\}) + P(\{HT\}) = \frac{1}{4} + \frac{1}{4} = \frac{2}{4} = \frac{1}{2} \]</span></p>
<p>Of course, in practice, you don’t have to write an event as a union of distinct events or outcomes before applying the law of addition. You can simply sum up the respective probability of each outcome in the event. For example, suppose we were interested in the probability of at least one head. In this case, a successful outcome would be HT, TH, or HH, whereas TT would be unsuccessful. Thus we are considering the probability of the event - <span class="math inline">\(C = \{HT, TH, HH\}\)</span>, and with the law of addition:</p>
<p><span class="math display" id="eq:setadd">\[
P(\{HT,TH, HH\}) = \frac{1}{4} + \frac{1}{4} + \frac{1}{4} = \frac{3}{4}
\tag{2.9}
\]</span></p>
<p>The law of addition makes things easier in multiple ways, and it implies another (easier!) way to calculate the probability above. With this in mind, we shall start with a handy property of the probability set function. Namely, for some sample space <span class="math inline">\(S\)</span>:</p>
<p><span class="math display" id="eq:setprop">\[ P(S) = 1
\tag{2.10}\]</span></p>
<p>In English, this means that the probability our outcome lands in the sample space is equal to 1. Of course this is true! The sample space is - by definition - the collection of all the possible outcomes of our random experiment. As I said, this property makes some computations easier. For example, suppose we are interested in the probability of getting at least one head (as above). In this case, we don’t need to go through the rigmarole of enumerating all the combinations with an H. We know there’s exactly one combination with no heads - TT - and the rest of the outcomes (the complement of TT) have at least one H. So, let’s say that the event <span class="math inline">\(C\)</span> contains the outcomes with at least one head, and let’s also say that <span class="math inline">\(S\)</span> is our full sample space:</p>
<p>Observe that:
<span class="math display">\[ C \cup \{TT\} = S \]</span>
Look back at the definition of our two-coin flip space, and you’ll see why I’m right about this. So then we can do this:</p>
<p><span class="math display">\[
\begin{align}
P(C \cup \{TT\}) &amp;= P(S) = 1 \\
P(C) + P(\{TT\}) &amp;= 1 \\
P(C) + P(\{TT\}) - P(\{TT\}) &amp;= 1 - P(\{TT\}) \\
P(C) &amp;= 1 - P(\{TT\}) \\
P(C) &amp;= 1 - \frac{1}{4} = \frac{3}{4}
\end{align}
\]</span></p>
<p>So without listing out all the permutations of heads and tails for our two coins, we’ve calculated what we need. That is to say, sometimes it’s much easier to calculate the probability of the complement (in the case above TT) of our event of interest and subtract the probability from 1. To more formally describe this, given some event <span class="math inline">\(C\)</span>:</p>
<p><span class="math display" id="eq:pcomplement">\[
P(C) = 1 - P(C^c)
\tag{2.11}
\]</span></p>
<p>Let’s work in another example of this just to hammer things home. Let’s say we have a sample space <span class="math inline">\(S = \{0,1,2,3,4,5,6,7,8,9,10\}\)</span>, and the probability set operator assigns a probability of 1/11 to each outcome in this sample space. We want to know the probability that our draw will land in the event <span class="math inline">\(C = \{3 \leq X\}\)</span> - an outcome of 3 or more. You might be able to do this in your head. I’m personally too lazy to write out the law of addition for <span class="math inline">\(C\)</span>, so we’ll use <a href="set-theory-and-probability.html#eq:pcomplement">(2.11)</a>. First observe that</p>
<p><span class="math display">\[
C^c = \{0,1,2\}
\\
P(C^c) = \frac{1}{11} + \frac{1}{11} + \frac{1}{11} = \frac{3}{11}
\]</span>
And therefore</p>
<p><span class="math display">\[
\begin{align}
P(C) &amp;= 1 - P(C^c) \\
P(C) &amp;= 1 - \frac{3}{11} \\
P(C) &amp;= \frac{8}{11}
\end{align}
\]</span>
Much easier!</p>
<p>Okay, I have to stop the narrative now to tell you I have done a great misdeed. For the sake of simplicity I’ve told a small lie about the law of addition (I know: <span class="math inline">\(P({Hell}) &gt; 0\)</span>). Now it’s time for the truth, and I’ll show you what I’ve done. Let’s define our sample space to be <span class="math inline">\(S = \{A,B,C\}\)</span>, and suppose each outcome has a probability of 1/3. Define two events <span class="math inline">\(C_1 = \{A,B\}\)</span> and <span class="math inline">\(C_2 = \{B,C\}\)</span>. We would like to know the probability of our outcome landing in <span class="math inline">\(C_1\)</span> or <span class="math inline">\(C_2\)</span>. This sounds like a job for the law of or. However, remember our current version of the law only works for mutually exclusive sets, but <span class="math inline">\(C_1 \cap C_2 = \{B\}\)</span>. That is to say they aren’t mutually exclusive. We need to make a small addition to the law of addition.</p>
<p><span class="math display" id="eq:additionnon">\[
P(A \cup B) = P(A) + P(B) - P(A \cap B)
\tag{2.12}
\]</span></p>
<p>If we were to simply sum the events as if they were mutually exclusive, we would count the probability of <span class="math inline">\(C_1 \cap C_2 = {B}\)</span> twice. If you don’t believe me, look at this</p>
<p><span class="math display">\[
P(C_1) = P(\{A,B\}) = P(A) + P(B) \\
P(C_2) = P(\{B,C\}) = P(B) + P(C) \\
\]</span></p>
<p>So if we applied our first version of the law of addition, then</p>
<p><span class="math display">\[
\begin{align}
P(C_1 \cup C_2) &amp;= P(C_1) + P(C_2) \\
&amp;= P(A) + P(B) + P(B) + P(C) \\
&amp;= P(A) + 2P(B) + P(C)
\end{align}
\]</span></p>
<p><span class="math inline">\(P(B)\)</span> is the probability that the outcome of our random experiment falls in <span class="math inline">\(C_1\)</span> and <span class="math inline">\(C_2\)</span> , and we’ve got one too many! Why do we have one too many? Let’s take a step back and consider the set operation inside <span class="math inline">\(P(C_1 \cup C_2)\)</span>. If we do this set operation first, then we would see that a successful outcome is A, B, or C. In other words, we should really only be counting the probability of B one time. Indeed, if we counted the probability of B twice, we would end up with a nonsensical probability of 4/3. So let’s put it all together using the second (more complete) law of addition. Recall that we assigned a probability of 1/3 to each element in our sample space</p>
<p><span class="math display">\[
\begin{align}
P(C_1 \cup C_2) &amp;= P(C_1) + P(C_2) - P(C_1 \cap C_2) \\
P(C_1 \cup C_2) &amp;= P(\{A,B\}) + P(\{B,C\}) - P(\{B\}) \\
P(C_1 \cup C_2) &amp;= \frac{2}{3} + \frac{2}{3} - \frac{1}{3} = 1
\end{align}
\]</span></p>
<p>That fixed it! This version of the law of addition also highlights something I have been doing implicitly for the last couple of examples. You can execute the set operation within the probability set operator first, and then calculate the probability of the resulting event as in <a href="set-theory-and-probability.html#eq:setadd">(2.9)</a>, e.g., using the first law of addition I described for mutually exclusive events. In this case, for <span class="math inline">\(P(C_1 \cap C_2)\)</span>, we executed the intersect first and then calculated the probability of the resulting event (B) using the law of addition.</p>
<p>Using the full version of the law of addition helps to make clear why we can drop the last term for mutually exclusive sets <a href="set-theory-and-probability.html#eq:addlaw">(2.8)</a>. Suppose we have two mutually exclusive events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, each a subset of some sample space <span class="math inline">\(S\)</span>. Then, because they are mutually exclusive, <span class="math inline">\(A \cap B = \{\}\)</span>. And, indeed, the probability of the null set - <span class="math inline">\(P(\{\})\)</span> - is zero. You can’t draw nothing on a random experiment. So in the case of mutually exclusive events</p>
<p><span class="math display">\[P(A \cup B) = P(A) + P(B) - 0\]</span></p>
<p>What we just learned will serve as a nice initial step into probability. We shall close this session by further emphasizing that <span class="math inline">\(P(A \cup B)\)</span> can be thought of as the probability that our outcome lands in A OR B. On the other hand, <span class="math inline">\(P(A \cap B)\)</span> can be thought of as the probability our outcome is an element shared by A AND B. Indeed, although we can use our set operations and the probability set operator to calculate the ladder, there is another method that we will discuss next.</p>
</div>
<div id="conditional-probability-and-independence" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Conditional Probability and Independence<a href="set-theory-and-probability.html#conditional-probability-and-independence" class="anchor-section" aria-label="Anchor link to header"></a></h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/USERNAME/REPO/edit/BRANCH/01-settheoryandprobability.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["_main.pdf", "_main.epub"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
