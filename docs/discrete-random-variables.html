<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Discrete Random Variables | Behavioral Statistics: Theory and Application</title>
  <meta name="description" content="<p>This is a behavioral statistics textbook with additional mathematical depth
that I wish I had had prior to enrolling in my first graduate level behavior
statistics course.|</p>" />
  <meta name="generator" content="bookdown 0.45 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Discrete Random Variables | Behavioral Statistics: Theory and Application" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="<p>This is a behavioral statistics textbook with additional mathematical depth
that I wish I had had prior to enrolling in my first graduate level behavior
statistics course.|</p>" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Discrete Random Variables | Behavioral Statistics: Theory and Application" />
  
  <meta name="twitter:description" content="<p>This is a behavioral statistics textbook with additional mathematical depth
that I wish I had had prior to enrolling in my first graduate level behavior
statistics course.|</p>" />
  

<meta name="author" content="Paul Meinz, Ph.D" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="set-theory-and-probability.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/tabwid-1.1.3/tabwid.css" rel="stylesheet" />
<script src="libs/tabwid-1.1.3/tabwid.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Behavioral Statistics: Theory and Application</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#you-can-learn-statistics"><i class="fa fa-check"></i><b>0.1</b> You can learn statistics</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#why-i-wrote-this-book"><i class="fa fa-check"></i><b>0.2</b> Why I wrote this book</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#what-content-to-expect-in-this-book"><i class="fa fa-check"></i><b>0.3</b> What content to expect in this book</a></li>
<li class="chapter" data-level="0.4" data-path="index.html"><a href="index.html#what-youll-need-to-know-to-get-the-most-out-of-this-book"><i class="fa fa-check"></i><b>0.4</b> What you’ll need to know to get the most out of this book</a></li>
<li class="chapter" data-level="0.5" data-path="index.html"><a href="index.html#future-editions-of-this-book"><i class="fa fa-check"></i><b>0.5</b> Future editions of this book</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="set-theory-and-probability.html"><a href="set-theory-and-probability.html"><i class="fa fa-check"></i><b>1</b> Set Theory and Probability</a>
<ul>
<li class="chapter" data-level="1.1" data-path="set-theory-and-probability.html"><a href="set-theory-and-probability.html#sets-and-sample-spaces"><i class="fa fa-check"></i><b>1.1</b> Sets and Sample Spaces</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="set-theory-and-probability.html"><a href="set-theory-and-probability.html#repeated-samples"><i class="fa fa-check"></i><b>1.1.1</b> Repeated Samples</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="set-theory-and-probability.html"><a href="set-theory-and-probability.html#what-is-probability"><i class="fa fa-check"></i><b>1.2</b> What is probability?</a></li>
<li class="chapter" data-level="1.3" data-path="set-theory-and-probability.html"><a href="set-theory-and-probability.html#conditional-probability-and-independence"><i class="fa fa-check"></i><b>1.3</b> Conditional Probability and Independence</a></li>
<li class="chapter" data-level="1.4" data-path="set-theory-and-probability.html"><a href="set-theory-and-probability.html#extended-examples-of-probability"><i class="fa fa-check"></i><b>1.4</b> Extended Examples of Probability</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html"><i class="fa fa-check"></i><b>2</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="2.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#independence-of-discrete-random-variables"><i class="fa fa-check"></i><b>2.1</b> Independence of discrete random variables</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Behavioral Statistics: Theory and Application</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="discrete-random-variables" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapter 2</span> Discrete Random Variables<a href="discrete-random-variables.html#discrete-random-variables" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>As behavioral researchers, we are often studying a population of something. We might be interested in the percentage of individuals who like cats or the number of cats owned by the average individual. We might be interested in the average happiness level of a population of individuals and/or what makes them happy. The populations we study are often vaguely defined, e.g. as in the population of people who have received some experimental treatment. Here, we will begin to take these somewhat vague notions and make them concrete. It turns out that, when we are studying a population, we are really studying what statisticians call a <em>random variable</em>. In this chapter, we will pay particular attention to the <em>discrete random variable</em>.</p>
<p>To develop an initial understanding of random variables, it will be useful to start with an example. When we are in the process of conducting quantitative research (and statistics), we measure things in numbers. You may have noticed that our previous discussions of discrete sample spaces used non-numeric descriptions - e.g., <span class="math inline">\(S = \{H, T\}\)</span> in the case of a coin flip, etc. In practice, we shall map the values in a discrete sample space to numbers. This makes them easier to work with and describe. Moving back to our frequently referenced example of a coin flip, we might map heads to the value of 1 and tails to the value of 0. Our set of outcomes would then be described as <span class="math inline">\(S = \{1,0\}\)</span>. On a given random experiment within this space, the outcome may therefore be a 1 or 0 with each number corresponding to heads or tails, respectively.</p>
<p>Plainly speaking, what we have just described is a <em>discrete random variable</em> - a variable that assumes a <em>number</em> as a result of randomness. We shall map the members of our sample space to numbers. The set of these numbers is called the <em>space</em> of the random variable, and like the discrete sample space, the outcomes in the space of a discrete random variable are either finite or countable. Oftentimes, discrete random variables - and random variables more generally - are referred to by the capital letter <span class="math inline">\(X\)</span>. This variable will assume an outcome at the resolution of some random process, and for the sake of clarity, a potential <em>outcome</em> of this randomness is referred to symbolically by a lower case <span class="math inline">\(x\)</span>.</p>
<p>Indeed, because <span class="math inline">\(X\)</span> is a random variable, we shall need a concrete way of describing it’s randomness. Recall in the last chapter, we discussed the probability set operator - <span class="math inline">\(P()\)</span>. This operator assigns the probability to an outcome - <span class="math inline">\(x\)</span> - on the basis of a set of rules. At the time, I told you that we would discuss this “set of rules” later. Later is now. As we noted, the set of rules for the assignment of probability is called a probability distribution. In the case of a discrete random variable, this distribution is called a <em>probability mass function</em> (pmf) - <span class="math inline">\(p(x)\)</span> - where <span class="math inline">\(x\)</span> is used to reference a particular outcome in the space of <span class="math inline">\(X\)</span>.</p>
<p>Suppose we are looking to determine the probability of random variable <span class="math inline">\(X\)</span> attaining a specific value - <span class="math inline">\(x\)</span> - let’s say, for example, <span class="math inline">\(\{x|X = 1\}\)</span>. Here, <span class="math inline">\(\{x|X = 1\}\)</span> describes the set of outcomes (<span class="math inline">\(x\)</span>) in the space of <span class="math inline">\(X\)</span> where the random experiment results in 1. Indeed, it’s a small set composed of exactly one value - <span class="math inline">\(\{1\}\)</span>. With regards to the probability set operator, we might write <span class="math inline">\(P(\{x|X = x\})\)</span>, but that’s a pain. Instead, we will use the shorthand <span class="math inline">\(P(X = 1)\)</span>, or more generally <span class="math inline">\(P(X = x)\)</span>. Moreover, you might also be interested in a larger set described by an inequality - e.g. <span class="math inline">\(P(X &lt; 2)\)</span> - the probability of all the outcomes in the space of <span class="math inline">\(X\)</span> where our random experiment results in an outcome less than 2.</p>
<p>The set of rules the probability set operator uses (a.k.a, a probability mass function) are frequently described like this:</p>
<p><span class="math display">\[
P(X=x) = p(x) =
\begin{cases}
\frac{1}{2} &amp; x = 1 \\
\frac{1}{2} &amp; x = 0
\end{cases}
\]</span></p>
<p>Note that <span class="math inline">\(P(X = x)\)</span> and <span class="math inline">\(p(x)\)</span> mean the same thing - hence the equal sign. After the large curly-brace, you will see a row for each outcome in the space of <span class="math inline">\(X\)</span>. In that row you will find the probability for that outcome. For example, <span class="math inline">\(P(X = 1) = p(1) = 1/2\)</span>. The values of <span class="math inline">\(x\)</span> for which <span class="math inline">\(p(x) &gt; 0\)</span> are called the <em>support</em> of <span class="math inline">\(X\)</span>. The pmf of <span class="math inline">\(X\)</span> has two important properties. Specifically:</p>
<ol style="list-style-type: decimal">
<li><p>All the outcomes <span class="math inline">\(x\)</span> in the space of <span class="math inline">\(X\)</span> have a probability <span class="math inline">\(0 \leq p(x) \leq 1\)</span>. That is, all the outcomes in the space of <span class="math inline">\(X\)</span> must have a probability from 0 to 1.</p></li>
<li><p>Given the space <span class="math inline">\(S\)</span> of a random variable, <span class="math inline">\(P(S)\)</span> = 1. In other words, if we are conducting a random experiment by drawing a value from the space of <span class="math inline">\(X\)</span> (the set of all numeric outcomes for <span class="math inline">\(X\)</span>), the probability that it lands in <span class="math inline">\(S\)</span> is 1. This hearkens back to <a href="set-theory-and-probability.html#eq:setprop">(1.10)</a> in the previous section.</p></li>
</ol>
<p>In plain language these two properties mean that we can define the pmf of a random variable by taking a total of one unit of probability and spreading it across a set of outcomes (the support of <span class="math inline">\(X\)</span>). For example, you might give .25 probability to a value of 1, .5 to a value of 2, and .25 to a value of 3. Each outcome would have a value from 0 to 1, and their respective probabilities would sum to 1.</p>
<p>As previously stated, in this chapter we will dig into discrete random variables:
1. We shall start by discussing the independence of random variables - with the goal of framing an intuition for the concept.
2. We will then turn our attention to things researchers might want to know about discrete random variables (and random variables more generally)
3. And finally, we will discuss some random variables that are frequently found in behavioral research.</p>
<div id="independence-of-discrete-random-variables" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Independence of discrete random variables<a href="discrete-random-variables.html#independence-of-discrete-random-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The concept of independence is found frequently within the field of statistics. As you read on, you will find that it is essential to the derivation, understanding, and validity of some of the most fundamental things we shall learn in statistics. Therefore, it is nice to have a deeper understanding of it. The goal if this section is to frame an intuition of the independence of random variables. A deeper mathematical understanding shall be saved for your inevitable foray into mathematical statistics (no doubt after being inspired by this book to master the topic).</p>
<p>In the last chapter, we discussed the concept of the independence of <em>events</em> in a random experiment. We shall now discuss independence as it pertains to random variables. Suppose we have two random variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. Then we say the two events are independent if</p>
<p><span class="math display" id="eq:descreteind">\[
P(X_1 = x_1 \cap X_2 = x_2) = P(X_1 = x_1)P(X_2 = x_2)
\tag{2.1}
\]</span>
In other words, if two random variables are independent, the probability of <span class="math inline">\(X_1 = x_1\)</span> AND <span class="math inline">\(X_2 = x_2\)</span> is equal to the product of their respective probabilities. We’ve already seen examples of this. Recall in example <a href="set-theory-and-probability.html#exm:coins">1.20</a>, we flipped three coins <em>independently</em>. If we mapped the outcomes of each coin to 1 and 0 for heads and tails, respectively, then the three resulting random variables are independent in the sense of <a href="discrete-random-variables.html#eq:descreteind">(2.1)</a>.</p>
<p>With some algebraic manipulation of <a href="discrete-random-variables.html#eq:descreteind">(2.1)</a>, we can see that the definition of independence for random variables is very similar to the definition of independence for events</p>
<p><span class="math display">\[
\frac{P(X_1 = x_1 \cap X_2 = x_2)}{P(X_2 = x_2)}=P(X_1 = x_1)
\]</span>
And, perhaps not surprisingly, if the two random variables are not independent then</p>
<p><span class="math display">\[
\frac{P(X_1 = x_1 \cap X_2 = x_2)}{P(X_2 = x_2)} = P(X_1 = x_1|X_2 = x_2) \neq P(X_1 = x_1)
\]</span>
That is to say, similar to the dependence of events, an event in the space of one variable <em>changes</em> the probability of an event in the space of another variable. Well, it may help to know that you have already seen an example of this in the last chapter. Recall example <a href="set-theory-and-probability.html#exm:dice">1.22</a>, when we looked at the sum of two dice. In this case, let’s call the sum of our two dice the random variable <span class="math inline">\(Z\)</span> and call the values of the first dice <span class="math inline">\(X\)</span>. Using the table we created, and the law of addition, we can determine a probability distribution for <span class="math inline">\(Z\)</span> (try it yourself and see if you get the same thing as below)
<span class="math display">\[
P(Z=z) = p(z) =
\begin{cases}
1/16 &amp; z = 2 \\
2/16 &amp; z = 3 \\
3/16 &amp; z = 4 \\
4/16 &amp; z = 5 \\
3/16 &amp; z = 6 \\
2/16 &amp; z = 7 \\
1/16 &amp; z = 8
\end{cases}
\]</span>
Here you can see that the space of <span class="math inline">\(Z\)</span> are all the integers from 2 to 8. The most probable value is 5. Because we haven’t had much experience with random variables yet, it is also important to point out that this distribution (surprisingly or not surprisingly) has all the properties of a pmf. The probabilities of all the outcomes in the space of <span class="math inline">\(Z\)</span> sum to 1, and the probabilities are constrained between 0 and 1.</p>
<p>Now we are going to look <span class="math inline">\((P(Z = z|X = x))\)</span> and things will start to become clearer. Consider the case where <span class="math inline">\(X = 1\)</span>. What does the distribution of <span class="math inline">\(P(Z = z|X = 1)\)</span> look like? To determine this we shall calculate the conditional probability of each Z - <em>given</em> our first dice roll is a 1. We did this back in example <a href="set-theory-and-probability.html#exm:dice">1.22</a> for the specific value of <span class="math inline">\(Z = 3\)</span>, and now we shall do it here for every value (try it yourself)</p>
<p><span class="math display">\[
P(Z=z|X=1) = p(z|x=1) =
\begin{cases}
1/4 &amp; z = 2 \\
1/4 &amp; z = 3 \\
1/4 &amp; z = 4 \\
1/4 &amp; z = 5 \\
0 &amp; z = 6 \\
0 &amp; z = 7 \\
0 &amp; z = 8
\end{cases}
\]</span></p>
<p>Do you see what happens with the event <span class="math inline">\(X = 1\)</span>? The probability of <span class="math inline">\(Z\)</span> <em>changes</em> with a roll of a 1 on the first die. For example, getting a <span class="math inline">\(Z = 2\)</span> now has a whopping 1/4 chance, compared to a paltry 1/16 before the first dice was rolled. Moreover, the probability is now spread across only four values - <span class="math inline">\(\{2,3,4,5\}\)</span>. That is, the support of <span class="math inline">\(Z\)</span> - given <span class="math inline">\(X = 1\)</span> - is now 2, 3, 4, 5.</p>
<p>Carry this idea of independence forward as we discuss and become more sophisticated in statistics. As you will see, some of the most fundamental statistical concepts require an <em>assumption</em> of independence. In many cases, we shall assume that our random variables are independent to take advantage of some convenient mathematical properties associated with independence. We’ll see one of these convenient properties as soon as the next section.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="set-theory-and-probability.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/USERNAME/REPO/edit/BRANCH/02-discreterandomvariables.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["_main.pdf", "_main.epub"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
